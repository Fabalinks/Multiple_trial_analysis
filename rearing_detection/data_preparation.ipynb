{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for PCA-rearing-detection method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I planed to use the results from baseline detection methods to do the pca one, but it seems there is no need. You can find the data preparation part in PCA_detection_methods.ipynb, so no need to read this notebook.\n",
    "\n",
    "1. Already have a baseline methods to detect the rearing period\n",
    "2. Get the rearing time from the baseline method as the training set\n",
    "3. Train the PCA-rearing detection model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from base import MultiDaysBeaconPosition, BeaconPosition\n",
    "from scipy.stats import sem\n",
    "from utils.basic_utils import get_tags\n",
    "from utils.baseline_method import determine_rearing_period\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '../Data/Raw/'\n",
    "rat_id = 'FS10'\n",
    "rat_subdirectories = glob(root_path+rat_id+'/*/' )\n",
    "\n",
    "tags = get_tags(rat_subdirectories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data with different tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_tag = BeaconPosition(rat_subdirectories[tag_id], tags[tag_id], True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016694419627324594\n"
     ]
    }
   ],
   "source": [
    "unit_time = np.mean(this_tag.position_data[1:,0] - this_tag.position_data[:-1,0])\n",
    "print(unit_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prepare data given T, tau\n",
    "\n",
    "set T = 200 bins, tau = 10 bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameters\n",
    "save_fig = False # whether save the fig for the results\n",
    "\n",
    "T = 200\n",
    "tau = 10\n",
    "group_step = 20\n",
    "\n",
    "height_thresh = 0.6 # threshold for height/z to determine rearing\n",
    "\n",
    "# get some important value for variable \n",
    "xy_speed = np.insert(this_tag.speed,0,0) # speed on xy planar insert 0 at the beginning of the speed array to make the size same\n",
    "z_speed = np.divide(this_tag.position_data[1:,3] - this_tag.position_data[:-1,3], this_tag.position_data[1:,0] - this_tag.position_data[:-1,0])\n",
    "z_speed = np.insert(z_speed,0,0) # insert 0 at the beginning of the speed array to make the size same \n",
    "\n",
    "z = this_tag.position_data[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108578,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n"
     ]
    }
   ],
   "source": [
    "## inital goups\n",
    "group_lists = []\n",
    "\n",
    "for boundary in np.arange(0, T, group_step):\n",
    "    print(boundary)\n",
    "    group_lists.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tau_sample(features, tau = 10, step = 2):\n",
    "    '''\n",
    "    generate a list of tau length sample by slicing the window along the whole time series\n",
    "    features: [n,k]\n",
    "    \n",
    "    return : array in[k,m]\n",
    "    '''\n",
    "    # determine the size of the final output\n",
    "    \n",
    "    T = features.shape[0]\n",
    "    k = features.shape[1] # # of features interested in \n",
    "    tau_samples = []# np.zeros((tau + (T-tau)//step, k))\n",
    "    \n",
    "    for end_idx in np.arange(tau, T+1, step):\n",
    "        tau_samples.append(features[end_idx-tau: end_idx,:])\n",
    "    \n",
    "    \n",
    "    return np.vstack(np.array(tau_samples)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = T\n",
    "N = n*20\n",
    "\n",
    "for Begin in np.arange(0, z.shape[0],N):\n",
    "    fig, axis = plt.subplots(4,5, figsize = (19,16), sharey = True, sharex = True)\n",
    "    axis = axis.flatten()\n",
    "\n",
    "    fig.subplots_adjust(left=0.08, right=0.98, bottom=0.05, top=0.90,\n",
    "                        hspace=0.2, wspace=0.3)\n",
    "\n",
    "\n",
    "    begin_idxs = np.arange(Begin,Begin+N, n)\n",
    "\n",
    "    for i,begin_idx in enumerate(begin_idxs):\n",
    "        this_features = np.zeros((n,3))\n",
    "        this_features[:,0] = z[begin_idx: begin_idx+n]\n",
    "        this_features[:,1] = z_speed[begin_idx: begin_idx+n]\n",
    "        this_features[:,2] = xy_speed[begin_idx: begin_idx+n]\n",
    "        this_rearing = determine_rearing_period(this_features,height_thresh= height_thresh, zspeed_thresh=0.5, xspeed_drop_thresh=0.2, gap_tolerance= 5, total_tolerance=10, )\n",
    "        \n",
    "        ## put this rearing results to the right group\n",
    "        group_idx = int(len(this_rearing)/group_step)\n",
    "\n",
    "        # plot results\n",
    "    #     axis[i].plot(z[begin_idx: begin_idx+n],label ='height')\n",
    "    #     if len(this_rearing)>0:\n",
    "    #         x_bool = np.zeros(n) ==1\n",
    "    #         x_bool[this_rearing] = True\n",
    "    #         axis[i].fill_between(np.arange(0,n), 0.45, 0.80, alpha = 0.4, label = 'rearing period', where = x_bool, interpolate = True, step = 'mid')\n",
    "    #     axis[i].set_xlabel('time bins', fontsize = 14)\n",
    "    #     axis[i].set_ylabel('height', fontsize = 14)\n",
    "    #     # break\n",
    "        \n",
    "    #     axis[i].legend(loc =1)\n",
    "    #     #print(i)\n",
    "        \n",
    "    # title = 'Rearing period detection of rat %s, height thresh = %.2f, bins = [%d: %d]'%(rat_id, height_thresh, Begin, Begin+N)\n",
    "    # fig.suptitle(title, fontsize = 16)\n",
    "    # if save_fig:\n",
    "    #     fig.savefig('results/easy_method/%s/%s.png'%(rat_id, title), format ='png',)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_group_list(group_lists):\n",
    "    '''\n",
    "    organize the group list to be used in PCA\n",
    "    '''\n",
    "    group_len = []\n",
    "    for this_list in group_lists:\n",
    "        group_len.append(len(this_list))\n",
    "    min_len = np.min(group_len)\n",
    "    \n",
    "    # randomly choose min(group_len) samples \n",
    "    features_matrix = []\n",
    "    for i,this_list in enumerate(group_lists):\n",
    "        random_idx = np.random.choice(np.arange(0,group_len[i]),size = min_len, replace= False) # no replace\n",
    "        random_sample = np.asarray(this_list)[random_idx]\n",
    "        array_sample = np.hstack(np.hstack(random_sample)) # feature1 feature2 feature3\n",
    "        features_matrix.append(array_sample)\n",
    "    \n",
    "    return np.asarray(features_matrix)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = T\n",
    "# get the initial group list\n",
    "group_lists = []\n",
    "for boundary in np.arange(0, T+1, group_step):\n",
    "    group_lists.append([])\n",
    "    \n",
    "begin_idx = 0\n",
    "while begin_idx+n <= z.shape[0]:\n",
    "   \n",
    "    this_features = np.zeros((n,3))\n",
    "    this_features[:,0] = z[begin_idx: begin_idx+n]\n",
    "    this_features[:,1] = z_speed[begin_idx: begin_idx+n]\n",
    "    this_features[:,2] = xy_speed[begin_idx: begin_idx+n]\n",
    "    this_rearing = determine_rearing_period(this_features,height_thresh= height_thresh, zspeed_thresh=0.5, xspeed_drop_thresh=0.2, gap_tolerance= 5, total_tolerance=10, )\n",
    "    \n",
    "    ## put this rearing results to the right group\n",
    "    group_idx = int(len(this_rearing)/group_step)\n",
    "    \n",
    "    ## get the pca features\n",
    "    pca_features = np.zeros((n,3))\n",
    "    pca_features[:,0] = z[begin_idx: begin_idx+n]\n",
    "    pca_features[:,1] = this_tag.position_data[begin_idx: begin_idx+n, 6]\n",
    "    pca_features[:,2] = z_speed[begin_idx: begin_idx+n]\n",
    "    \n",
    "    tau_samples = generate_tau_sample(pca_features,tau= tau, step = 10)\n",
    "    \n",
    "    group_lists[group_idx].append(tau_samples)\n",
    "    \n",
    "    begin_idx+= n\n",
    "\n",
    "# combine the last two\n",
    "group_lists[-2].extend(group_lists[-1])\n",
    "group_lists = group_lists[:-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5acfd06c6f898409f916ab5083bf34cc1cb5dcab793d5fe060e2c2dd836cbac0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
